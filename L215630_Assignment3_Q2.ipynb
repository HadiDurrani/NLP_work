{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('urdu-sentiment-corpus-v1.tsv', delimiter='\\t')\n",
    "data.columns = ['Tweet', 'Class']\n",
    "data['Class'] = data['Class'].map({'P': 1, 'N': 0})\n",
    "data = data.dropna()\n",
    "data\n",
    "\n",
    "X = data['Tweet'].values\n",
    "y = data['Class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_len = max([len(seq) for seq in X_train + X_test])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=data['Tweet'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "word2vec_model.save(\"word2vec_urdu.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bilstm_model(embedding_matrix):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
    "    model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(100)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(model, X_test, y_test):\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "results = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'F1-Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 17s 533ms/step - loss: 0.6947 - accuracy: 0.5152 - val_loss: 0.6960 - val_accuracy: 0.3784\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 3s 272ms/step - loss: 0.6944 - accuracy: 0.4955 - val_loss: 0.6977 - val_accuracy: 0.4730\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 0.6926 - accuracy: 0.5258 - val_loss: 0.7019 - val_accuracy: 0.4865\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 292ms/step - loss: 0.6932 - accuracy: 0.4758 - val_loss: 0.7018 - val_accuracy: 0.4730\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 302ms/step - loss: 0.6916 - accuracy: 0.5167 - val_loss: 0.7062 - val_accuracy: 0.4865\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 3s 304ms/step - loss: 0.6915 - accuracy: 0.5045 - val_loss: 0.6998 - val_accuracy: 0.4730\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 297ms/step - loss: 0.6898 - accuracy: 0.5182 - val_loss: 0.7058 - val_accuracy: 0.4730\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 3s 303ms/step - loss: 0.6880 - accuracy: 0.5394 - val_loss: 0.7110 - val_accuracy: 0.4730\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 3s 300ms/step - loss: 0.6966 - accuracy: 0.4909 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 3s 301ms/step - loss: 0.6910 - accuracy: 0.5258 - val_loss: 0.6945 - val_accuracy: 0.5270\n",
      "8/8 [==============================] - 3s 40ms/step\n",
      "                 Accuracy  Precision    Recall  F1-Score\n",
      "BiLSTM_Word2Vec  0.485714   0.444444  0.064516  0.112676\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec.load(\"word2vec_urdu.model\")\n",
    "word_vectors = word2vec_model.wv\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word_vectors:\n",
    "        embedding_matrix[i] = word_vectors[word]\n",
    "\n",
    "bilstm_model = create_bilstm_model(embedding_matrix)\n",
    "bilstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
    "\n",
    "acc, precision, recall, f1 = evaluate_classifier(bilstm_model, X_test, y_test)\n",
    "\n",
    "results.loc['BiLSTM_Word2Vec'] = [acc, precision, recall, f1]\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 543ms/step - loss: 0.6954 - accuracy: 0.4742 - val_loss: 0.6935 - val_accuracy: 0.5270\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.6905 - accuracy: 0.5348 - val_loss: 0.6974 - val_accuracy: 0.5135\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 280ms/step - loss: 0.6854 - accuracy: 0.5485 - val_loss: 0.7173 - val_accuracy: 0.5135\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 296ms/step - loss: 0.6850 - accuracy: 0.5515 - val_loss: 0.6997 - val_accuracy: 0.5270\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 295ms/step - loss: 0.6806 - accuracy: 0.5515 - val_loss: 0.7023 - val_accuracy: 0.4459\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 3s 303ms/step - loss: 0.6751 - accuracy: 0.5470 - val_loss: 0.6959 - val_accuracy: 0.5405\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 309ms/step - loss: 0.6705 - accuracy: 0.5621 - val_loss: 0.7109 - val_accuracy: 0.5270\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 3s 307ms/step - loss: 0.6601 - accuracy: 0.5530 - val_loss: 0.6783 - val_accuracy: 0.5811\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.6580 - accuracy: 0.5606 - val_loss: 0.7135 - val_accuracy: 0.5405\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 0.6501 - accuracy: 0.5652 - val_loss: 0.6810 - val_accuracy: 0.5676\n",
      "8/8 [==============================] - 3s 38ms/step\n",
      "                 Accuracy  Precision    Recall  F1-Score\n",
      "BiLSTM_Word2Vec  0.485714   0.444444  0.064516  0.112676\n",
      "BiLSTM_Glove     0.477551   0.416667  0.080645  0.135135\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "bilstm_model = create_bilstm_model(embedding_matrix)\n",
    "bilstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
    "acc, precision, recall, f1 = evaluate_classifier(bilstm_model, X_test, y_test)\n",
    "results.loc['BiLSTM_Glove'] = [acc, precision, recall, f1]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 24s 1s/step - loss: 0.6955 - accuracy: 0.4833 - val_loss: 0.6884 - val_accuracy: 0.5541\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 9s 782ms/step - loss: 0.6937 - accuracy: 0.5076 - val_loss: 0.6900 - val_accuracy: 0.5541\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 9s 786ms/step - loss: 0.6935 - accuracy: 0.4955 - val_loss: 0.6913 - val_accuracy: 0.5541\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 9s 799ms/step - loss: 0.6925 - accuracy: 0.5091 - val_loss: 0.6890 - val_accuracy: 0.5541\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 9s 778ms/step - loss: 0.6944 - accuracy: 0.5045 - val_loss: 0.6904 - val_accuracy: 0.5541\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 9s 782ms/step - loss: 0.6926 - accuracy: 0.5212 - val_loss: 0.6897 - val_accuracy: 0.5541\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 9s 776ms/step - loss: 0.6942 - accuracy: 0.5045 - val_loss: 0.6895 - val_accuracy: 0.5541\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 9s 789ms/step - loss: 0.6948 - accuracy: 0.5121 - val_loss: 0.6906 - val_accuracy: 0.5405\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 9s 772ms/step - loss: 0.6944 - accuracy: 0.4818 - val_loss: 0.6927 - val_accuracy: 0.5811\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 8s 763ms/step - loss: 0.6935 - accuracy: 0.5106 - val_loss: 0.6902 - val_accuracy: 0.5541\n",
      "8/8 [==============================] - 3s 64ms/step\n",
      "                 Accuracy  Precision    Recall  F1-Score\n",
      "BiLSTM_Word2Vec  0.485714   0.444444  0.064516  0.112676\n",
      "BiLSTM_Glove     0.477551   0.416667  0.080645  0.135135\n",
      "BiLSTM_fastText  0.493878   0.000000  0.000000  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DURRANI\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_sentences = [sentence.split() for sentence in X]\n",
    "fasttext_model = FastText(X_sentences, vector_size=32, min_count=1)\n",
    "fasttext_dict = {word: fasttext_model.wv[word] for word in fasttext_model.wv.index_to_key}\n",
    "embedding_matrix = np.zeros((5000, 32))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = fasttext_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "bilstm_model = create_bilstm_model(embedding_matrix)\n",
    "bilstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
    "\n",
    "acc, precision, recall, f1 = evaluate_classifier(bilstm_model, X_test, y_test)\n",
    "\n",
    "results.loc['BiLSTM_fastText'] = [acc, precision, recall, f1]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
